---
title: "BRA_Metabolism"
output: html_document
---

The following script uses StreamMetabolizer to estimate GPP and ER rates at the Brandywine stations.
Installation details. OMIT if necessary
```{r setup, include=FALSE}
remotes::install_github('appling/unitted') #sometimes Rcpp has no binary version yet, if so, don't update from source versions, instead, say no to the source compilation and install the most recent binary version
remotes::install_github("USGS-R/streamMetabolizer") #directly from Git so we get the most recent version

#other necessary packages: 
pack_list<-list ("Rtools","rstan")
for(i in 1:length(pack_list)){
  p <- pack_list[[i]]
  install.packages(p,repos = "https://cran.rstudio.com",dependencies = TRUE)
}

```



#Data input must follow strict format:
i) will download DO, T, and depth form USGS
ii) gaps and anomalies are filled with our data
iii) PAR comes form SWRC weather station
iv) DOsat concentration is calculated from temperature data prior to analysis
```{r}
library(streamMetabolizer) ; library(unitted) ; library(lubridate) ; library(dplyr) ; library(dataRetrieval)
# file input is named as stormfiles: e.g., BAM_A_1Apr2019
```


#Adjust dates of interest and station
```{r}
# first, we need to download USGS data, merge with PAR and inspect for gaps/outliers in DO

########################add here the dates for each storm event and site ######################################################
startQdate = "2019-3-1"
endQdate = "2020-12-31"
siteQcode = "01481000" #01481000 for BAM and 01481500 for WILMA
file.name= "BAM_do.csv"
pCodes = list("00060", "00300", "00010" )
```


#Gather data and format
```{r}
Met_data_original = as.data.frame(seq(ymd_hm('2019-03-01 00:00'),ymd_hm('2020-12-31 23:45'), by = '15 mins')) #creature the full date vector a priori, when merging with the data will allow us to identify and keep NAs
colnames(Met_data_original) <- c("date")
Met_data_original$date <- lubridate::force_tz(Met_data_original$date, 'Etc/GMT+5') #transform into EST

for (i in 1:3) {

siteNo <- siteQcode
pCode <- pCodes[[i]]
start.date <- startQdate
end.date <- endQdate 
####retrieve data every 15min
        BAM_q <- readNWISuv(siteNumbers = siteNo, 
                            parameterCd = pCode, 
                            startDate = start.date, 
                            endDate = end.date,tz = "EST") 

Qtemp = BAM_q[,3:4]; colnames(Qtemp)<-c("date","par")
Met_data_original = inner_join(Met_data_original,Qtemp, by ="date")

}

Met_data_original = Met_data_original [,1:4]
colnames(Met_data_original) <- c("date", "Q" , "DO" , "Temp")

JIC_data = Met_data_original
#add miniDOT DO data
miniDOTdata = read.csv("C:/Users/mpeipoch/Dropbox/manuscripts/RiverPlankton/working_files/miniDOT_WILMA.csv")
miniDOTdata$date = as.POSIXct(miniDOTdata$date, format="%m/%d/%Y %H:%M", tz='America/New_York')
temp_data <- full_join(miniDOTdata, Met_data_original, by = "date")
temp_data$S1 <- dplyr::coalesce(temp_data[["DO.x"]],  temp_data[["DO.y"]])
temp_data$S2 <- dplyr::coalesce(temp_data[["Temp.x"]],  temp_data[["Temp.y"]])

   
Met_data_original = temp_data %>%
  select(.,date,Q,S1,S2) 
colnames(Met_data_original) <- c("date" , "Q" , "DO" , "Temp")
Met_data_original = Met_data_original[complete.cases(Met_data_original),]
Met_data_original = arrange(Met_data_original, date)

#add PAR data (umol m^-2 s^-1) from SWRC
PARdata = read.csv("C:/Users/mpeipoch/Dropbox/manuscripts/RiverPlankton/working_files/PARdata_smt_add.csv")
PARdata$date = as.POSIXct(PARdata$date, format="%m/%d/%Y %H:%M", tz='America/New_York')
PARdata = PARdata[,1:2] #drop variables that we don't need
Met_data_original = left_join(Met_data_original,PARdata, by ="date")


#calculate DOsat from 
#WILMA-----------------Met_data_original$pressure = rep((1011.929),nrow(Met_data_original))
Met_data_original$pressure = rep((0.9906*1.01325*1000),nrow(Met_data_original))
Met_data_original$DOsat = calc_DO_sat(temp=u(Met_data_original$Temp,"degC"), press=u(Met_data_original$pressure,"mb"), sal=u(0,"PSU")) # units are checked


#to calculate depth from discharge
Met_data_original$Q = Met_data_original$Q*0.028316846592
#WILMA----------------Met_data_original$depth<- 0.7273*(Met_data_original$Q^0.294)
Met_data_original$depth<-calc_depth(Q = u(Met_data_original$Q, "m^3 s^-1"), c = u(0.409, "m"), f = u(0.294, ""))


#format date column as needed
str(Met_data_original[,1]) #just to make sure that date is in a POSIXct format, as default from dateRetrieval::readNWISuv
posix.time.localtz = Met_data_original$date
lubridate::tz(posix.time.localtz) #should be "Etc/GMT+5
Met_data_original$solar.time <- streamMetabolizer::calc_solar_time(posix.time.localtz, longitude=-75)

Met_data = Met_data_original %>%
  select(.,solar.time,DO, DOsat,depth,Temp,par) 
  
#rename columns in the final dataset
colnames(Met_data) <- c("solar.time" , "DO.obs" , "DO.sat" , "depth" , "temp.water" , "light")


#round numbers for depth and PAR
Met_data$DO.sat = round(Met_data$DO.sat,2)
Met_data$depth = round(Met_data$depth,1)
Met_data$light = round(Met_data$light,0)


#add units (transforms into a tibbble)
unitats<-c(	"", "mgO2 L^-1" ,	"mgO2 L^-1"	, "m"	, "degC" , "umol m^-2 s^-1") #attach units and form a unitted data.frame
dat_unitted<-u(Met_data, units = unitats)
dat_unitted[c(1,48,96,240,288),] #check that numbers are of right magnitude according to the supposed units 

Met_data2 = Met_data[-c(1028,1070,2455),]
Met_data2 = Met_data[!duplicated(Met_data$solar.time),]
```

#Alternative----------------------------Gather data FROM USGS ONLY and format
```{r}
Met_data_original = as.data.frame(seq(ymd_hm('2019-03-01 00:00'),ymd_hm('2020-11-30 23:45'), by = '15 mins')) #creature the full date vector a priori, when merging with the data will allow us to identify and keep NAs
colnames(Met_data_original) <- c("date")
Met_data_original$date <- lubridate::force_tz(Met_data_original$date, 'Etc/GMT+5') #transform into EST

for (i in 1:3) {

siteNo <- siteQcode
pCode <- pCodes[[i]]
start.date <- startQdate
end.date <- endQdate 
####retrieve data every 15min
        BAM_q <- readNWISuv(siteNumbers = siteNo, 
                            parameterCd = pCode, 
                            startDate = start.date, 
                            endDate = end.date,tz = "EST") 

Qtemp = BAM_q[,3:4]; colnames(Qtemp)<-c("date","par")
Met_data_original = inner_join(Met_data_original,Qtemp, by ="date")

}

Met_data_original = Met_data_original [,1:4]
colnames(Met_data_original) <- c("date", "Q" , "DO" , "Temp")

#add PAR data (umol m^-2 s^-1) from SWRC
PARdata = read.csv("C:/Users/mpeipoch/Dropbox/manuscripts/RiverPlankton/working_files/PARdata_smt_add.csv")
PARdata$date = as.POSIXct(PARdata$date, format="%m/%d/%Y %H:%M", tz='America/New_York')
PARdata = PARdata[,1:2] #drop variables that we don't need
Met_data_original = left_join(Met_data_original,PARdata, by ="date")


#calculate DOsat from 
#WILMA-----------------------Met_data_original$pressure = rep((1011.929),nrow(Met_data_original))
Met_data_original$pressure = rep((0.9906*1.01325*1000),nrow(Met_data_original))
Met_data_original$DOsat = calc_DO_sat(temp=u(Met_data_original$Temp,"degC"), press=u(Met_data_original$pressure,"mb"), sal=u(0,"PSU")) # units are checked


#to calculate depth from discharge
Met_data_original$Q = Met_data_original$Q*0.028316846592 
#WILMA------------------------Met_data_original$depth<- 0.7273*(Met_data_original$Q^0.294)
Met_data_original$depth<-calc_depth(Q = u(Met_data_original$Q, "m^3 s^-1"), c = u(0.409, "m"), f = u(0.294, ""))


#format date column as needed
str(Met_data_original[,1]) #just to make sure that date is in a POSIXct format, as default from dateRetrieval::readNWISuv
posix.time.localtz = Met_data_original$date
lubridate::tz(posix.time.localtz) #should be "Etc/GMT+5
Met_data_original$solar.time <- streamMetabolizer::calc_solar_time(posix.time.localtz, longitude=-75)

Met_data = Met_data_original %>%
  select(.,solar.time,DO, DOsat,depth,Temp,par) 
  
#rename columns in the final dataset
colnames(Met_data) <- c("solar.time" , "DO.obs" , "DO.sat" , "depth" , "temp.water" , "light")


#round numbers for depth and PAR
Met_data$DO.sat = round(Met_data$DO.sat,2)
Met_data$depth = round(Met_data$depth,1)
Met_data$light = round(Met_data$light,0)


#add units (transforms into a tibbble)
unitats<-c(	"", "mgO2 L^-1" ,	"mgO2 L^-1"	, "m"	, "degC" , "umol m^-2 s^-1") #attach units and form a unitted data.frame
dat_unitted<-u(Met_data, units = unitats)
dat_unitted[c(1,48,96,240,288),] #check that numbers are of right magnitude according to the supposed units 


```

#Visualization of raw data to ensure data input is all right
```{r}
library(ggplot2); library(dplyr) ; library(tidyr) ;  library(rstan)
#DO percent saturation and concentration
dat_unitted%>% unitted::v() %>%
  mutate(DO.pctsat = 100 * (DO.obs / DO.sat)) %>%
  select(solar.time, starts_with('DO')) %>%
  gather(type, DO.value, starts_with('DO')) %>%
  mutate(units=ifelse(type == 'DO.pctsat', 'DO\n(% sat)', 'DO\n(mg/L)')) %>%
  ggplot(aes(x=solar.time, y=DO.value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

###ASSESS IF THERE ARE ANY MAJOR DATA GAPS AND PATCH mininDOT data as needed


#depth,water temperature, and light
labels <- c(depth='depth\n(m)', temp.water='water temp\n(deg C)', light='PAR\n(umol m^-2 s^-1)')
dat_unitted %>% unitted::v() %>%
  select(solar.time, depth, temp.water, light) %>%
  gather(type, value, depth, temp.water, light) %>%
  mutate(
    type=ordered(type, levels=c('depth','temp.water','light')),
    units=ordered(labels[type], unname(labels))) %>%
  ggplot(aes(x=solar.time, y=value, color=type)) + geom_line() + 
  facet_grid(units ~ ., scale='free_y') + theme_bw() +
  scale_color_discrete('variable')

```

#Run the model
```{r}
mle_BRA <- mm_name(type='mle', ode_method='trapezoid')
mle_specs <- specs(mle_BRA, init.GPP.daily= 2,init.ER.daily = -2,init.K600.daily = 4  )
mle_specs #inspect and refine as needed
mm_mle_BRA <- metab(mle_specs, data=dat_unitted, info=c(site='BRA', source='MPG'))

#examine results
plot_DO_preds(mm_mle_BRA)
plot_metab_preds(mm_mle_BRA)
mle_mydata.s_daily<-get_params(mm_mle_BRA)

#check for collinearity between ER and K600
output2<-get_params(mm_mle_BRA)
par(mar = c(5,5,1,1))
plot<-plot(output2$K600.daily,output2$ER.daily,xlab =expression("Daily"~K[600]~(d^{-1})),
           pch=16,cex=1.5,col='black',
           ylab=expression("Daily ER" ~ (g ~ O[2]~m^{-2} ~d^{-1})),
           cex.lab=1.2)
m = lm(ER.daily ~ K600.daily, data=output2)
summary(m)

file.path = "C:/Users/mpeipoch/Dropbox/manuscripts/RiverPlankton/working_files/metabolism"
write.csv(mle_mydata.s_daily,file = paste(file.path, file.name, sep = "/")) #
write.csv(Met_data,file = "C:/Users/mpeipoch/Dropbox/manuscripts/RiverPlankton/working_files/metabolism/temp.csv") #
mle_mydata.s_daily
```



