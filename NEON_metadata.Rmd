---
title: "NEON_data"
author: "MPG"
date: "9/29/2020"
output: html_document
---



*Using package 'neonUtilities' to compile NEON water quality data*
Pairing Wikiwaterhsed metadata for each NEON site in the continetnal US (24) with avergae chl/turbidity concentrations
```{r setup, include=FALSE}
library(neonUtilities) ; library(data.table) ; library(dplyr)

sites = list("ARIK", "BIGC","BLDE","BLUE","BLWA","COMO","FLNT","HOPB","KING","LECO","LEWI","MART","MAYF","MCDI","MCRA","PRIN","REDB","SYCA","TECR","TOMB","WALK","WLOU")
     
for(i in 1:length(sites)){ 
  
siteNEON = sites[[i]] #change this manually for each site
  
waterChem = loadByProduct(dpID="DP1.20288.001", site=c(siteNEON), startdate="2016-04", enddate="2020-08", check.size = FALSE) #water quality data including chl and turbidity

#extract data from downloaded files
chem_data = as.data.frame(waterChem[[4]])

#subset each dataset, normalize datetime, and merge
chem_data_subset = chem_data[, c("startDateTime","chlorophyll","turbidity")]
chem_data_subset = chem_data_subset[complete.cases(chem_data_subset), ] #remove NAs
rownames(chem_data_subset) <- NULL #remove rownames 

#need to validate the time zone used in original data: 
waterChem[[3]] #look for yyyy-MM-dd'T'HH:mm:ss'Z' to confirm UTC
chem_data_subset$datetime = as.vector(as.POSIXct(chem_data_subset$startDateTime, format="%m/%d/%y %H:%M:%S", tz="UTC"))

#reshape datetime vector into 30min intervals
a <- as.vector(chem_data_subset$datetime)
chem_data_subset$datetime <-as.vector(as.POSIXlt(round(as.double(a)/(30*60))*(30*60),
                                        origin=(as.POSIXlt('1970-01-01')), 
                                        tz="UTC"))

#convert date from 'POSIXlt' class to 'double' to allow aggregation with dplyr
chem_data_subset$datetime <- as.double(chem_data_subset$datetime) 

#aggregate by date 
chem_data_subset30m = chem_data_subset %>%
  group_by(datetime) %>%
  summarize(chl.avg = min(chlorophyll, na.rm = TRUE), turb.avg = min(turbidity, na.rm = TRUE)) #taking the min and not the mean to deal with weird data jumps between 30 second intervals in original data

#reformat datetime back prior merging with flow data
chem_data_subset30m$datetime <- as.POSIXct(chem_data_subset30m$datetime, format="%m/%d/%Y %H:%M:%S", 
                                           origin=(as.POSIXlt('1970-01-01')),
                                           tz="UTC")

#build a new data frame with average chl and turb to which I'll add metadata and compile multiple sites
avg.chl.storm = chem_data_subset30m %>% 
            filter(turb.avg > quantile(turb.avg, probs = c(.95))) %>% #storm data is subseted as being of trubidity higher than 95 percentile
            filter(chl.avg > 0 & chl.avg < 100) %>% #remove negative chl values
            summarize(., n())

avg.chl.baseflow = chem_data_subset30m %>% 
            filter(., turb.avg < quantile(turb.avg, probs = c(.25))) %>% #baseflow data is subseted as being of trubidity lower than 25 percentile
            filter(chl.avg > 0 & chl.avg < 100) %>% #remove negative chl values
            summarize(., n())


#get the metadata
setwd ("C:/Users/mpeipoch/Dropbox/NSF_PLANKTON_2020/NEON/metadata")
indiv_site_channel = read.csv(paste0(siteNEON,"_","channel.csv", collapse = NULL))
indiv_site_landuse = read.csv(paste0(siteNEON,"_","landuse.csv", collapse = NULL))
  
length.site = as.vector(sum(as.numeric(as.vector(indiv_site_channel[1:10,2]))))
slope.site = as.vector(indiv_site_channel[nrow(indiv_site_channel),3])
forest.site = sum(indiv_site_landuse[8:10,4])
ag.site = sum(indiv_site_landuse[13:14,4]) #pasture and crops
developed.site = sum(indiv_site_landuse[3:6,4])
chl_range= avg.chl.storm - avg.chl.baseflow

site.df = data.frame(siteNEON,length.site,slope.site,forest.site,ag.site,developed.site,avg.chl.baseflow,avg.chl.storm,chl_range )
colnames(site.df) = c("siteID","channel length","channel slope","forest_cover","ag_cover","urban_cover","chl_base","chl_storm","chl_range" )

compiled.NEON.site.metadata = rbind(site.df, compiled.NEON.site.metadata)

}

```

```{r}
write.csv(compiled.NEON.site.metadata, file = "C:/Users/mpeipoch/Dropbox/NSF_PLANKTON_2020/NEON/metadata.csv")

compiled.NEON.site.metadata = data.frame()
```
